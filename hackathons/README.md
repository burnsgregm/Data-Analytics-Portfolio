# Hackathon & Competition Projects

This folder contains projects completed as part of competitive data science events. These notebooks showcase end-to-end machine learning workflows under tight deadlines, from exploratory data analysis and feature engineering to model tuning and submission.

---

### 1. Restaurant Annual Turnover Prediction (2nd Place Finish)

* **Event:** Great Learning Hackathon (June 2025) 
* **Objective:** To build a machine learning model to accurately predict the annual turnover of restaurants across India based on a diverse set of features.
* **Approach:** The project involved comprehensive exploratory data analysis (EDA), advanced feature engineering (including log transformation of the target variable and creating interaction terms), and robust model validation using 5-Fold Cross-Validation. 
* **Technologies Used:** Python, Pandas, Scikit-learn, CatBoost, XGBoost, and Optuna for Bayesian hyperparameter tuning. 
* **Outcome:** **Secured 2nd Place out of 107 participating teams.** The final, highest-ranking submission was a fine-tuned CatBoostRegressor model. 

---

### 2. Kaggle's Spaceship Titanic: Survival Prediction

* **Event:** Kaggle Competition 
* **Objective:** A binary classification task to predict which passengers were "transported to an alternate dimension" following a spacetime anomaly, based on passenger and spaceship data. 
* **Approach:** The project involved detailed EDA, data imputation to handle missing values, feature engineering (such as creating a 'GroupSize' feature), and the training and comparison of a full suite of classification models. 
* **Technologies Used:** Python, Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn (Logistic Regression, KNN, SVM, Decision Tree, Random Forest), XGBoost, CatBoost, and Ensemble Methods (Voting Classifier). 
* **Outcome:** A highly accurate ensemble model was developed for the final submission, combining the predictive power of several fine-tuned classifiers to maximize the competition score. 
